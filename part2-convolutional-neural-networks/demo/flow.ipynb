{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RAFT' from 'RAFT' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27080/1467989014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mRAFT\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRAFT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mflow_viz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'RAFT' from 'RAFT' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('RAFT/core')\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from RAFT import RAFT\n",
    "from utils import flow_viz\n",
    "\n",
    "\n",
    "def frame_preprocess(frame, device):\n",
    "    frame = torch.from_numpy(frame).permute(2, 0, 1).float()\n",
    "    frame = frame.unsqueeze(0)\n",
    "    frame = frame.to(device)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def vizualize_flow(img, flo, save, counter):\n",
    "    # permute the channels and change device is necessary\n",
    "    img = img[0].permute(1, 2, 0).cpu().numpy()\n",
    "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # map flow to rgb image\n",
    "    flo = flow_viz.flow_to_image(flo)\n",
    "    flo = cv2.cvtColor(flo, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # concatenate, save and show images\n",
    "    img_flo = np.concatenate([img, flo], axis=0)\n",
    "    if save:\n",
    "        cv2.imwrite(f\"demo_frames/frame_{str(counter)}.jpg\", img_flo)\n",
    "    cv2.imshow(\"Optical Flow\", img_flo / 255.0)\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == 27:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_cpu_model(model):\n",
    "    new_model = OrderedDict()\n",
    "    # get all layer's names from model\n",
    "    for name in model:\n",
    "        # create new name and update new model\n",
    "        new_name = name[7:]\n",
    "        new_model[new_name] = model[name]\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def inference(args):\n",
    "    # get the RAFT model\n",
    "    model = RAFT(args)\n",
    "    # load pretrained weights\n",
    "    pretrained_weights = torch.load(args.model)\n",
    "\n",
    "    save = args.save\n",
    "    if save:\n",
    "        if not os.path.exists(\"demo_frames\"):\n",
    "            os.mkdir(\"demo_frames\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        # parallel between available GPUs\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        # load the pretrained weights into model\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        # change key names for CPU runtime\n",
    "        pretrained_weights = get_cpu_model(pretrained_weights)\n",
    "        # load the pretrained weights into model\n",
    "        model.load_state_dict(pretrained_weights)\n",
    "\n",
    "    # change model's mode to evaluation\n",
    "    model.eval()\n",
    "\n",
    "    video_path = args.video\n",
    "    # capture the video and get the first frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame_1 = cap.read()\n",
    "\n",
    "    # frame preprocessing\n",
    "    frame_1 = frame_preprocess(frame_1, device)\n",
    "\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            # read the next frame\n",
    "            ret, frame_2 = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # preprocessing\n",
    "            frame_2 = frame_preprocess(frame_2, device)\n",
    "            # predict the flow\n",
    "            flow_low, flow_up = model(frame_1, frame_2, iters=args.iters, test_mode=True)\n",
    "            # transpose the flow output and convert it into numpy array\n",
    "            ret = vizualize_flow(frame_1, flow_up, save, counter)\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_1 = frame_2\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--model\", help=\"restore checkpoint\")\n",
    "    parser.add_argument(\"--iters\", type=int, default=12)\n",
    "    parser.add_argument(\"--video\", type=str, default=\"./videos/car.mp4\")\n",
    "    parser.add_argument(\"--save\", action=\"store_true\", help=\"save demo frames\")\n",
    "    parser.add_argument(\"--small\", action=\"store_true\", help=\"use small model\")\n",
    "    parser.add_argument(\n",
    "        \"--mixed_precision\", action=\"store_true\", help=\"use mixed precision\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    inference(args)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98393cdabe821fa5276deeff2609ab236a18bb0acff879b009cb9063c8de4d36"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
